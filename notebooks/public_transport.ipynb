{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import openrouteservice as ors\n",
    "import folium\n",
    "import sys\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from threading import Semaphore\n",
    "import json\n",
    "import folium\n",
    "import openrouteservice\n",
    "import json\n",
    "import time\n",
    "import openrouteservice\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import shape\n",
    "from geopy.distance import geodesic\n",
    "from shapely import wkt\n",
    "from openrouteservice.exceptions import ApiError\n",
    "sys.path.append('../scripts')\n",
    "from utilities import get_vic_subs_as_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = ors.Client(key='5b3ce3597851110001cf624828f2b63314b24af798ed8608d8464d19')\n",
    "client = ors.Client(key='5b3ce3597851110001cf62485538e6b62c8b41f7a68feb510f25a05e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/curated/m_curr_pred_median.csv'\n",
    "output_file = '../data/curated/house_transport_part_2.csv'\n",
    "with open(input_file, 'r') as file:\n",
    "    data = pd.read_csv(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rate limit\n",
    "RATE_LIMIT = 100  # Requests per minute\n",
    "REQUEST_INTERVAL = 60 / RATE_LIMIT  # Interval between requests in seconds\n",
    "\n",
    "# Semaphore to control the number of concurrent requests\n",
    "semaphore = Semaphore(3)  # Max number of concurrent threads\n",
    "def get_coordinates(address):\n",
    "    try:\n",
    "        with semaphore:\n",
    "            response = client.pelias_search(address)\n",
    "            if response['features']:\n",
    "                coords = response['features'][0]['geometry']['coordinates']\n",
    "                return {'latitude': coords[1], 'longitude': coords[0]}\n",
    "            else:\n",
    "                return {'latitude': None, 'longitude': None}\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching coordinates for address '{address}': {e}\")\n",
    "        return (coords[1], coords[0])\n",
    "\n",
    "def worker(row):\n",
    "    address = row.get('address') \n",
    "    if address:\n",
    "        coords = get_coordinates(address)\n",
    "        return coords\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Add a column 'geometry' to store (latitude, longitude) tuples\n",
    "df['geometry'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find coordinates based on address for houses\n",
    "max_threads = 3\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:\n",
    "    # Create a list of futures for each row\n",
    "    futures = {executor.submit(worker, row): index for index, row in list(df.iterrows())[3500:]}\n",
    "\n",
    "    # Wrap futures with tqdm to show progress\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing items\"):\n",
    "        index = futures[future]\n",
    "        try:\n",
    "            # Update the 'geometry' column for each row\n",
    "            df.at[index, 'geometry'] = future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {index}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated data with coordinates saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_file_1 = '../data/curated/house_transport_part_2.csv'\n",
    "housing_file_2 = '../data/curated/house_transport.csv'\n",
    "df1 = pd.read_csv(housing_file_1)\n",
    "df2 = pd.read_csv(housing_file_2)\n",
    "\n",
    "# Ensure the geometry column is updated by filling missing values from the second DataFrame\n",
    "# This assumes the 'address' column is the same in both files and is used for merging\n",
    "df1['geometry'] = df1['geometry'].combine_first(df2['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved to: ../data/curated/merged_houses_with_complete_geometry.csv\n"
     ]
    }
   ],
   "source": [
    "merged_file = '../data/curated/merged_houses_with_complete_geometry.csv'\n",
    "df1.to_csv(merged_file, index=False)\n",
    "\n",
    "print(f\"Merged file saved to: {merged_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_coordinates = []\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    geometry = row['geometry']\n",
    "    \n",
    "    # Check if geometry is in dictionary format with 'latitude' and 'longitude' keys\n",
    "    if isinstance(geometry, str):\n",
    "        try:\n",
    "            # Convert string representation of dictionary to actual dictionary\n",
    "            geometry_dict = eval(geometry)\n",
    "            \n",
    "            if 'latitude' in geometry_dict and 'longitude' in geometry_dict:\n",
    "                latitude = geometry_dict['latitude']\n",
    "                longitude = geometry_dict['longitude']\n",
    "                houses_coordinates.append({\n",
    "                    'address': row['address'],\n",
    "                    'coordinates': (latitude, longitude)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Missing latitude or longitude for house: {row['address']}, geometry: {geometry}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing geometry for house: {row['address']}, error: {e}\")\n",
    "    else:\n",
    "        print(f\"Invalid geometry format for house: {row['address']}, geometry: {geometry}\")\n",
    "\n",
    "# Now houses_coordinates contains all the valid house addresses and their coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_regional = gpd.read_file(\"../data/PTV/\", layer='PTV_REGIONAL_TRAIN_STATION')\n",
    "gdf_regional = gdf_regional.to_crs(epsg=4326)\n",
    "\n",
    "gdf_metro = gpd.read_file(\"../data/PTV/\", layer='PTV_METRO_TRAIN_STATION')\n",
    "gdf_metro = gdf_metro.to_crs(epsg=4326)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_tram = gpd.read_file(\"../data/PTV_tram_bus/\", layer='PTV_METRO_TRAM_STOP')\n",
    "gdf_tram = gdf_tram.to_crs(epsg=4326)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_station_data(gdf):\n",
    "    return gdf[['geometry', 'STOP_ID', 'STOP_NAME']].apply(\n",
    "        lambda row: ((row['geometry'].y, row['geometry'].x), row['STOP_ID'], row['STOP_NAME']), axis=1\n",
    "    ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_station_gdf = gpd.GeoDataFrame(pd.concat([gdf_metro, gdf_regional], ignore_index=True))\n",
    "tram_station_gdf = gpd.GeoDataFrame(gdf_tram)\n",
    "\n",
    "train_station_data = prepare_station_data(train_station_gdf)\n",
    "tram_station_data = prepare_station_data(tram_station_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_file = '../data/curated/merged_houses_with_complete_geometry.csv'\n",
    "houses_df = pd.read_csv(housing_file)\n",
    "\n",
    "# Convert 'geometry' column to a usable format\n",
    "houses_df['geometry'] = houses_df['geometry'].apply(eval) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_station(house_coords, stations):\n",
    "    closest_station = None\n",
    "    min_distance = float('inf')\n",
    "    closest_station_id = None\n",
    "    closest_station_name = None\n",
    "    \n",
    "    for (station_coords, station_id, station_name) in stations:\n",
    "        distance = geodesic(house_coords, station_coords).kilometers\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_station = station_coords\n",
    "            closest_station_id = station_id\n",
    "            closest_station_name = station_name\n",
    "            \n",
    "    return closest_station, closest_station_id, closest_station_name, min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 houses...\n",
      "Processed 2000 houses...\n",
      "Processed 3000 houses...\n",
      "Processed 4000 houses...\n",
      "Processed 5000 houses...\n",
      "Processed 6000 houses...\n",
      "Merged data with closest stations saved to: ../data/curated/houses_with_closest_stations.csv\n"
     ]
    }
   ],
   "source": [
    "for idx, row in houses_df.iterrows():\n",
    "    house_coords = (row['geometry']['latitude'], row['geometry']['longitude'])\n",
    "    \n",
    "    # Find the closest train station\n",
    "    closest_train_station_coords, closest_train_station_id, closest_train_station_name, train_distance = find_closest_station(house_coords, train_station_data)\n",
    "    \n",
    "    # Find the closest tram station\n",
    "    closest_tram_station_coords, closest_tram_station_id, closest_tram_station_name, tram_distance = find_closest_station(house_coords, tram_station_data)\n",
    "    \n",
    "    # Update the DataFrame with closest station data\n",
    "    houses_df.at[idx, 'closest_train_station_name'] = closest_train_station_name\n",
    "    houses_df.at[idx, 'closest_train_station_distance_km'] = train_distance\n",
    "    houses_df.at[idx, 'closest_tram_station_name'] = closest_tram_station_name\n",
    "    houses_df.at[idx, 'closest_tram_station_distance_km'] = tram_distance\n",
    "    \n",
    "    # Print progress every 1000 houses\n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"Processed {idx + 1} houses...\")\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file = '../data/curated/houses_with_closest_stations.csv'\n",
    "houses_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Merged data with closest stations saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_location(house_coords, locations):\n",
    "    closest_location = None\n",
    "    min_distance = float('inf')\n",
    "    closest_location_id = None\n",
    "    closest_location_name = None\n",
    "    \n",
    "    for (location_coords, location_id, location_name) in locations:\n",
    "        distance = geodesic(house_coords, location_coords).kilometers\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_location = location_coords\n",
    "            closest_location_id = location_id\n",
    "            closest_location_name = location_name\n",
    "            \n",
    "    return closest_location, closest_location_id, closest_location_name, min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_file = '../data/raw/vic_hospitals_with_coordinates.csv'\n",
    "hospitals_df = pd.read_csv(hospital_file)\n",
    "\n",
    "# Convert 'geometry' column from string to list format\n",
    "hospitals_df['geometry'] = hospitals_df['geometry'].apply(eval)\n",
    "\n",
    "# Create a list of hospital coordinates, IDs, and names for proximity search\n",
    "hospital_data = [((row['geometry'][1], row['geometry'][0]), row['Establishment ID'], row['Hospital name']) \n",
    "                 for idx, row in hospitals_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in houses_df.iterrows():\n",
    "    house_coords = (row['geometry']['latitude'], row['geometry']['longitude'])\n",
    "    \n",
    "    # Find closest hospital\n",
    "    closest_hospital_coords, closest_hospital_id, closest_hospital_name, hospital_distance = find_closest_location(house_coords, hospital_data)\n",
    "    \n",
    "    # Update DataFrame with closest hospital data\n",
    "    houses_df.at[idx, 'closest_hospital_name'] = closest_hospital_name\n",
    "    houses_df.at[idx, 'closest_hospital_distance_km'] = hospital_distance\n",
    "    \n",
    "    # Print progress every 1000 houses\n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"Processed {idx + 1} houses...\")\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file = '../data/curated/houses_with_closest_stations_and_hospital.csv'\n",
    "houses_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data with closest hospitals saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with dropped columns saved to: ../data/curated/houses_with_closest_stations_and_hospital.csv\n"
     ]
    }
   ],
   "source": [
    "houses_df = houses_df.drop(columns=['2025', '2026', '2027'])\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file = '../data/curated/houses_with_closest_stations_and_hospital.csv'\n",
    "houses_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data with dropped columns saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
